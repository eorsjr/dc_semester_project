{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f8cf996",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e855f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0db4cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "import dc_semester_project.compressor as compressor\n",
    "import dc_semester_project.decompressor as decompressor\n",
    "import dc_semester_project.checker as checker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeba633d",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "944e8f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_folder = \"../data/samples\"\n",
    "compressed_folder = \"../data/compressed\"\n",
    "decompressed_folder = \"../data/decompressed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad76e6",
   "metadata": {},
   "source": [
    "## Clean folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd9d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_folders():\n",
    "    for folder in [compressed_folder, decompressed_folder]:\n",
    "        if os.path.exists(folder):\n",
    "            for filename in os.listdir(folder):\n",
    "                file_path = os.path.join(folder, filename)\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "        else:\n",
    "            # Create the folder if it doesn't exist\n",
    "            os.makedirs(folder)\n",
    "            print(f\"Created folder: {folder}\")\n",
    "\n",
    "    print(\"Data folders cleaned successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85142850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folders cleaned successfully!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_folders()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7fefeb",
   "metadata": {},
   "source": [
    "## Examination of Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec7e47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: sample1.data\n",
      "\n",
      "Entropy: -0.00 bits per byte\n",
      "\n",
      "\n",
      "Processing file: sample.bmp\n",
      "\n",
      "Entropy: 2.29 bits per byte\n",
      "\n",
      "\n",
      "Processing file: sample1b.data\n",
      "\n",
      "Entropy: 0.00 bits per byte\n",
      "\n",
      "\n",
      "Processing file: sample7.data\n",
      "\n",
      "Entropy: 7.69 bits per byte\n",
      "\n",
      "\n",
      "Processing file: sample.RW2\n",
      "\n",
      "Entropy: 7.53 bits per byte\n",
      "\n",
      "\n",
      "Processing file: sample5b.data\n",
      "\n",
      "Entropy: 8.00 bits per byte\n",
      "\n",
      "\n",
      "Processing file: sample6.data\n",
      "\n",
      "Entropy: 8.00 bits per byte\n",
      "\n",
      "\n",
      "Processing file: sample5.data\n",
      "\n",
      "Entropy: 8.00 bits per byte\n",
      "\n",
      "\n",
      "Processing file: sample4.data\n",
      "\n",
      "Entropy: 0.40 bits per byte\n",
      "\n",
      "\n",
      "Processing file: sample3.data\n",
      "\n",
      "Entropy: 1.00 bits per byte\n",
      "\n",
      "\n",
      "Processing file: sample2.data\n",
      "\n",
      "Entropy: 8.00 bits per byte\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(samples_folder):\n",
    "        if filename.endswith(\".DS_Store\"):\n",
    "            continue\n",
    "        print(f\"Processing file: {filename}\\n\")\n",
    "        original_file_path = os.path.join(samples_folder, filename)\n",
    "        checker.entropy(original_file_path)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a098768",
   "metadata": {},
   "source": [
    "## Tests with LZ77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e17d4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = \"lz77\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acd895f",
   "metadata": {},
   "source": [
    "### Testing on provided .data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a242baca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folders cleaned successfully!\n",
      "\n",
      "Processing file: sample1.data\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz77\n",
      "File decompressed and saved to: ../data/decompressed/decompressed_sample1.data\n",
      "The original and decompressed files are identical.\n",
      "Original size: 1000000 bytes\n",
      "Compressed size: 381142 bytes\n",
      "Compression ratio: 2.62\n",
      "\n",
      "\n",
      "Processing file: sample1b.data\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz77\n",
      "File decompressed and saved to: ../data/decompressed/decompressed_sample1b.data\n",
      "The original and decompressed files are identical.\n",
      "Original size: 1000000 bytes\n",
      "Compressed size: 381142 bytes\n",
      "Compression ratio: 2.62\n",
      "\n",
      "\n",
      "Processing file: sample7.data\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz77\n",
      "File decompressed and saved to: ../data/decompressed/decompressed_sample7.data\n",
      "The original and decompressed files are identical.\n",
      "Original size: 1000000 bytes\n",
      "Compressed size: 6881406 bytes\n",
      "Compression ratio: 0.15\n",
      "\n",
      "\n",
      "Processing file: sample5b.data\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz77\n",
      "File decompressed and saved to: ../data/decompressed/decompressed_sample5b.data\n",
      "The original and decompressed files are identical.\n",
      "Original size: 1000000 bytes\n",
      "Compressed size: 387344 bytes\n",
      "Compression ratio: 2.58\n",
      "\n",
      "\n",
      "Processing file: sample6.data\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz77\n",
      "File decompressed and saved to: ../data/decompressed/decompressed_sample6.data\n",
      "The original and decompressed files are identical.\n",
      "Original size: 1000000 bytes\n",
      "Compressed size: 6974576 bytes\n",
      "Compression ratio: 0.14\n",
      "\n",
      "\n",
      "Processing file: sample5.data\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz77\n",
      "File decompressed and saved to: ../data/decompressed/decompressed_sample5.data\n",
      "The original and decompressed files are identical.\n",
      "Original size: 1000000 bytes\n",
      "Compressed size: 7436459 bytes\n",
      "Compression ratio: 0.13\n",
      "\n",
      "\n",
      "Processing file: sample4.data\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz77\n",
      "File decompressed and saved to: ../data/decompressed/decompressed_sample4.data\n",
      "The original and decompressed files are identical.\n",
      "Original size: 1000000 bytes\n",
      "Compressed size: 716804 bytes\n",
      "Compression ratio: 1.40\n",
      "\n",
      "\n",
      "Processing file: sample3.data\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz77\n",
      "File decompressed and saved to: ../data/decompressed/decompressed_sample3.data\n",
      "The original and decompressed files are identical.\n",
      "Original size: 1000000 bytes\n",
      "Compressed size: 1483347 bytes\n",
      "Compression ratio: 0.67\n",
      "\n",
      "\n",
      "Processing file: sample2.data\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz77\n",
      "File decompressed and saved to: ../data/decompressed/decompressed_sample2.data\n",
      "The original and decompressed files are identical.\n",
      "Original size: 1000000 bytes\n",
      "Compressed size: 8003112 bytes\n",
      "Compression ratio: 0.12\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_folders()\n",
    "\n",
    "\n",
    "for filename in os.listdir(samples_folder):\n",
    "    if filename.endswith(\".data\"):\n",
    "        \n",
    "        print(f\"Processing file: {filename}\\n\")\n",
    "        \n",
    "        # Construct file paths\n",
    "        original_file_path = os.path.join(samples_folder, filename)\n",
    "        compressed_file_path = f\"{compressed_folder}/compressed.{algorithm}\"\n",
    "        decompressed_file_path = f\"{decompressed_folder}/decompressed_{filename}\"\n",
    "\n",
    "        # Compression\n",
    "        compressor.compress_file(original_file_path, algorithm=algorithm, output_path=compressed_file_path)\n",
    "\n",
    "        # Decompression\n",
    "        decompressor.decompress_file(compressed_file_path, output_path=decompressed_file_path, algorithm=algorithm)\n",
    "\n",
    "        # Verification\n",
    "        checker.checker(original_file_path, decompressed_file_path)\n",
    "\n",
    "        # Compression ratio\n",
    "        checker.compression_ratio(original_file_path, compressed_file_path)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1463ec8a",
   "metadata": {},
   "source": [
    "### Testing on .RW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f718f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folders cleaned successfully!\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz77\n",
      "File decompressed and saved to: ../data/decompressed/decompressed.RW2\n",
      "The original and decompressed files are identical.\n",
      "Original size: 36087808 bytes\n",
      "Compressed size: 253434491 bytes\n",
      "Compression ratio: 0.14\n"
     ]
    }
   ],
   "source": [
    "clean_folders()\n",
    "\n",
    "ext = \".RW2\"\n",
    "original_file_path = f\"{samples_folder}/sample{ext}\"\n",
    "decompressed_file_path = f\"{decompressed_folder}/decompressed{ext}\"\n",
    "compressed_file_path = f\"{compressed_folder}/compressed.{algorithm}\"\n",
    "\n",
    "\n",
    "# Compression\n",
    "compressor.compress_file(original_file_path, algorithm=algorithm, output_path=compressed_file_path)\n",
    "\n",
    "# Decompression\n",
    "decompressor.decompress_file(compressed_file_path, output_path=decompressed_file_path, algorithm=algorithm)\n",
    "\n",
    "# Verification\n",
    "checker.checker(original_file_path, decompressed_file_path)\n",
    "\n",
    "# Compression ratio\n",
    "checker.compression_ratio(original_file_path, compressed_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da51760",
   "metadata": {},
   "source": [
    "### Testing on .bmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce97e211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folders cleaned successfully!\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz77\n",
      "File decompressed and saved to: ../data/decompressed/decompressed.bmp\n",
      "The original and decompressed files are identical.\n",
      "Original size: 28125138 bytes\n",
      "Compressed size: 10719076 bytes\n",
      "Compression ratio: 2.62\n"
     ]
    }
   ],
   "source": [
    "clean_folders()\n",
    "\n",
    "ext = \".bmp\"\n",
    "original_file_path = f\"{samples_folder}/sample{ext}\"\n",
    "decompressed_file_path = f\"{decompressed_folder}/decompressed{ext}\"\n",
    "compressed_file_path = f\"{compressed_folder}/compressed.{algorithm}\"\n",
    "\n",
    "\n",
    "# Compression\n",
    "compressor.compress_file(original_file_path, algorithm=algorithm, output_path=compressed_file_path)\n",
    "\n",
    "# Decompression\n",
    "decompressor.decompress_file(compressed_file_path, output_path=decompressed_file_path, algorithm=algorithm)\n",
    "\n",
    "# Verification\n",
    "checker.checker(original_file_path, decompressed_file_path)\n",
    "\n",
    "# Compression ratio\n",
    "checker.compression_ratio(original_file_path, compressed_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae23dca",
   "metadata": {},
   "source": [
    "## Test with LZ78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "843f2cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = \"lz78\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c29812",
   "metadata": {},
   "source": [
    "### Testing on provided .data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3100fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folders cleaned successfully!\n",
      "\n",
      "Processing file: sample1.data\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz78\n",
      "File decompressed and saved to: ../data/decompressed/decompressed_sample1.data\n",
      "The original and decompressed files are identical.\n",
      "Original size: 1000000 bytes\n",
      "Compressed size: 9662 bytes\n",
      "Compression ratio: 103.50\n",
      "\n",
      "\n",
      "Processing file: sample1b.data\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz78\n",
      "File decompressed and saved to: ../data/decompressed/decompressed_sample1b.data\n",
      "The original and decompressed files are identical.\n",
      "Original size: 1000000 bytes\n",
      "Compressed size: 9671 bytes\n",
      "Compression ratio: 103.40\n",
      "\n",
      "\n",
      "Processing file: sample7.data\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz78\n",
      "File decompressed and saved to: ../data/decompressed/decompressed_sample7.data\n",
      "The original and decompressed files are identical.\n",
      "Original size: 1000000 bytes\n",
      "Compressed size: 3478848 bytes\n",
      "Compression ratio: 0.29\n",
      "\n",
      "\n",
      "Processing file: sample5b.data\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz78\n",
      "File decompressed and saved to: ../data/decompressed/decompressed_sample5b.data\n",
      "The original and decompressed files are identical.\n",
      "Original size: 1000000 bytes\n",
      "Compressed size: 224768 bytes\n",
      "Compression ratio: 4.45\n",
      "\n",
      "\n",
      "Processing file: sample6.data\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz78\n",
      "File decompressed and saved to: ../data/decompressed/decompressed_sample6.data\n",
      "The original and decompressed files are identical.\n",
      "Original size: 1000000 bytes\n",
      "Compressed size: 3324981 bytes\n",
      "Compression ratio: 0.30\n",
      "\n",
      "\n",
      "Processing file: sample5.data\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz78\n",
      "File decompressed and saved to: ../data/decompressed/decompressed_sample5.data\n",
      "The original and decompressed files are identical.\n",
      "Original size: 1000000 bytes\n",
      "Compressed size: 3169582 bytes\n",
      "Compression ratio: 0.32\n",
      "\n",
      "\n",
      "Processing file: sample4.data\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz78\n",
      "File decompressed and saved to: ../data/decompressed/decompressed_sample4.data\n",
      "The original and decompressed files are identical.\n",
      "Original size: 1000000 bytes\n",
      "Compressed size: 201569 bytes\n",
      "Compression ratio: 4.96\n",
      "\n",
      "\n",
      "Processing file: sample3.data\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz78\n",
      "File decompressed and saved to: ../data/decompressed/decompressed_sample3.data\n",
      "The original and decompressed files are identical.\n",
      "Original size: 1000000 bytes\n",
      "Compressed size: 487109 bytes\n",
      "Compression ratio: 2.05\n",
      "\n",
      "\n",
      "Processing file: sample2.data\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz78\n",
      "File decompressed and saved to: ../data/decompressed/decompressed_sample2.data\n",
      "The original and decompressed files are identical.\n",
      "Original size: 1000000 bytes\n",
      "Compressed size: 190942 bytes\n",
      "Compression ratio: 5.24\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_folders()\n",
    "\n",
    "\n",
    "for filename in os.listdir(samples_folder):\n",
    "    if filename.endswith(\".data\"):\n",
    "        \n",
    "        print(f\"Processing file: {filename}\\n\")\n",
    "        \n",
    "        # Construct file paths\n",
    "        original_file_path = os.path.join(samples_folder, filename)\n",
    "        compressed_file_path = f\"{compressed_folder}/compressed.{algorithm}\"\n",
    "        decompressed_file_path = f\"{decompressed_folder}/decompressed_{filename}\"\n",
    "\n",
    "        # Compression\n",
    "        compressor.compress_file(original_file_path, algorithm=algorithm, output_path=compressed_file_path)\n",
    "\n",
    "        # Decompression\n",
    "        decompressor.decompress_file(compressed_file_path, output_path=decompressed_file_path, algorithm=algorithm)\n",
    "\n",
    "        # Verification\n",
    "        checker.checker(original_file_path, decompressed_file_path)\n",
    "\n",
    "        # Compression ratio\n",
    "        checker.compression_ratio(original_file_path, compressed_file_path)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b025d33d",
   "metadata": {},
   "source": [
    "### Testing on .RW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90172934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folders cleaned successfully!\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz78\n",
      "File decompressed and saved to: ../data/decompressed/decompressed.RW2\n",
      "The original and decompressed files are identical.\n",
      "Original size: 36087808 bytes\n",
      "Compressed size: 95511455 bytes\n",
      "Compression ratio: 0.38\n"
     ]
    }
   ],
   "source": [
    "clean_folders()\n",
    "\n",
    "ext = \".RW2\"\n",
    "original_file_path = f\"{samples_folder}/sample{ext}\"\n",
    "decompressed_file_path = f\"{decompressed_folder}/decompressed{ext}\"\n",
    "compressed_file_path = f\"{compressed_folder}/compressed.{algorithm}\"\n",
    "\n",
    "\n",
    "# Compression\n",
    "compressor.compress_file(original_file_path, algorithm=algorithm, output_path=compressed_file_path)\n",
    "\n",
    "# Decompression\n",
    "decompressor.decompress_file(compressed_file_path, output_path=decompressed_file_path, algorithm=algorithm)\n",
    "\n",
    "# Verification\n",
    "checker.checker(original_file_path, decompressed_file_path)\n",
    "\n",
    "# Compression ratio\n",
    "checker.compression_ratio(original_file_path, compressed_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3b1665",
   "metadata": {},
   "source": [
    "### Testing on .bmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d745e355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folders cleaned successfully!\n",
      "\n",
      "File compressed and saved to: ../data/compressed/compressed.lz78\n",
      "File decompressed and saved to: ../data/decompressed/decompressed.bmp\n",
      "The original and decompressed files are identical.\n",
      "Original size: 28125138 bytes\n",
      "Compressed size: 171387 bytes\n",
      "Compression ratio: 164.10\n"
     ]
    }
   ],
   "source": [
    "clean_folders()\n",
    "\n",
    "ext = \".bmp\"\n",
    "original_file_path = f\"{samples_folder}/sample{ext}\"\n",
    "decompressed_file_path = f\"{decompressed_folder}/decompressed{ext}\"\n",
    "compressed_file_path = f\"{compressed_folder}/compressed.{algorithm}\"\n",
    "\n",
    "\n",
    "# Compression\n",
    "compressor.compress_file(original_file_path, algorithm=algorithm, output_path=compressed_file_path)\n",
    "\n",
    "# Decompression\n",
    "decompressor.decompress_file(compressed_file_path, output_path=decompressed_file_path, algorithm=algorithm)\n",
    "\n",
    "# Verification\n",
    "checker.checker(original_file_path, decompressed_file_path)\n",
    "\n",
    "# Compression ratio\n",
    "checker.compression_ratio(original_file_path, compressed_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21f909e",
   "metadata": {},
   "source": [
    "## Results (.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c71ee7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Entropy (bits per byte)</th>\n",
       "      <th>Compression Ratio (LZ77)</th>\n",
       "      <th>Compression Ratio (LZ78)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample1.data</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.62</td>\n",
       "      <td>103.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample1b.data</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.62</td>\n",
       "      <td>103.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample2.data</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample3.data</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample4.data</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.40</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sample5.data</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sample5b.data</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2.58</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sample6.data</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sample7.data</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sample.RW2</td>\n",
       "      <td>7.53</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sample.bmp</td>\n",
       "      <td>2.29</td>\n",
       "      <td>2.62</td>\n",
       "      <td>164.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File  Entropy (bits per byte)  Compression Ratio (LZ77)  \\\n",
       "0    sample1.data                     0.00                      2.62   \n",
       "1   sample1b.data                     0.00                      2.62   \n",
       "2    sample2.data                     8.00                      0.12   \n",
       "3    sample3.data                     1.00                      0.67   \n",
       "4    sample4.data                     0.40                      1.40   \n",
       "5    sample5.data                     8.00                      0.13   \n",
       "6   sample5b.data                     8.00                      2.58   \n",
       "7    sample6.data                     8.00                      0.14   \n",
       "8    sample7.data                     7.69                      0.15   \n",
       "9      sample.RW2                     7.53                      0.14   \n",
       "10     sample.bmp                     2.29                      2.62   \n",
       "\n",
       "    Compression Ratio (LZ78)  \n",
       "0                     103.50  \n",
       "1                     103.40  \n",
       "2                       5.24  \n",
       "3                       2.05  \n",
       "4                       4.69  \n",
       "5                       0.32  \n",
       "6                       4.45  \n",
       "7                       0.30  \n",
       "8                       0.29  \n",
       "9                       0.38  \n",
       "10                    164.10  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../data/entropy_compression - Sheet1.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scientific_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
